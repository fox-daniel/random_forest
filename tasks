Tasks:


COMMIT PATCHES as carrying out the following: 

4. clean up code according to: https://imankulov.name/posts/python-cleanup/
	- revise README according to models listed
	- update requirements file or yml file
	- format code with 'black' (learn to use from command line)
	- remove unused imports
	- remove unused variables
	- follow PEP-8 naming conventions
	- run pylint
	- remove debugging prints
	- remove commented-out code
	
5. put my code into a deliverable form that can be opened and run on another machine with one command (after unzipping)
6. test on GCP or AWS virtual machine
7. numba functions
7.05 update yml file for conda env 
7.1 cProfile decision_tree.py and revise accordingly
7.2 retest on GCP or AWS VM
7.3 incorporate pruning into decision tree
8. redo the analysis that onethreebio asked for with my better code
9. Send to CDO (Cory) and ask for feedback and permission to post on Kaggle etc
10. make github repo public
11. post my results to Kaggle (the dataset onethreebio gave me came from Kaggle and there are a bunch of analyses there, not sure any use the modified random forest)

Optional:

Revise dt alg: tree data structure should be a pair of lists: 
	tree = [[non-terminal-nodes],[terminal-nodes]] so that only the non-terminal-nodes are split with each call to branch() (OR put a T/F flag in each node to indicate if terminal) 


